{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f08cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "#data_dir = \"sam_data/sa_000020/image_dir\"\n",
    "data_dir = \"/home/ubuntu/MySAM/sam_data/mini_image_dir/image_dir\"#fix me\n",
    "image_path_iter = DataLoader(os.listdir(data_dir), batch_size=2, shuffle=True)\n",
    "#image_paths = \n",
    "#image_iter = DataLoader(ImageFolder(data_dir, transform=transforms.ToTensor()), batch_size=2, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed692b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def load_image(image_path, root_dir):\n",
    "    #image_path = \"/home/ubuntu/sam_data/sa_000020/mini_image_dir/train/sam:1.jpg\"\n",
    "    image = cv2.imread(''.join([root_dir, '/', image_path]))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return torch.from_numpy(image).permute(2, 0, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4269106",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = data_dir.split('/')\n",
    "paths[-1] = 'embedding_dir'\n",
    "embedding_dir = \"/\".join(paths)\n",
    "if not os.path.exists(embedding_dir):\n",
    "    os.mkdir(embedding_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8688e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process one batch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    from build_sam import sam_model_registry\n",
    "    teacher_model_checkpoint_path = 'model_checkpoint/sam_vit_h_4b8939.pth'\n",
    "    teacher_model = sam_model_registry['default'](teacher_model_checkpoint_path)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    _ = teacher_model.to(device)\n",
    "    for batch_path in image_path_iter:\n",
    "        input_images = torch.stack([teacher_model.preprocess(load_image(path, data_dir).to(device)) for path in batch_path])\n",
    "        #input_images = torch.stack([teacher_model.preprocess(image[0].to(device)) for image in batch_image])\n",
    "        #pdb.set_trace()\n",
    "        teacher_emd = teacher_model.image_encoder(input_images)\n",
    "        for image_file_name, embed in zip(batch_path, teacher_emd):\n",
    "            target_path = ''.join([embedding_dir, '/', image_file_name.split('.')[0], '.pth'])\n",
    "            torch.save(embed, target_path)\n",
    "        print(\"process one batch\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd57c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd16da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
